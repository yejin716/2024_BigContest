import streamlit as st 
import pandas as pd
import torch
import os
import json
from PIL import Image
##################################################################api
from dotenv import load_dotenv
import google.generativeai as genai
##################################################################vectordb
from langchain_chroma import Chroma
##################################################################embedding
from langchain_huggingface import HuggingFaceEmbeddings
from defs_single import (clear_chat_history, main)

#.env íŒŒì¼ ìƒì„±í•´ì„œ GEMINI_API_KEY=API_KEY ì…ë ¥ í›„ ì‹¤í–‰í•˜ì‹œë©´ë¼ìš”
load_dotenv()

gemini_api_key = os.getenv('GEMINI_API_KEY')
genai.configure(api_key=gemini_api_key)

##################################################################
#chatbot UI
st.set_page_config(page_title='ì œì£¼ë„ ë§›ì§‘', page_icon="ğŸ†",initial_sidebar_state="expanded")
st.title('ì œì£¼ë„ ìŒì‹ì  íƒë°©!')
st.subheader("ëˆ„êµ¬ë‘ ì œì£¼ë„ ì™”ë‚˜ìš”? ë§ì¶¤ ì œì£¼ë„ ë§›ì§‘ ì¶”ì²œí•´ë“œë ¤ìš”~")

st.write("")

st.write("#ì—°ì¸#ì•„ì´#ì¹œêµ¬#ë¶€ëª¨ë‹˜#í˜¼ì#ë°˜ë ¤ë™ë¬¼ #ë°ì´íŠ¸#ë‚˜ë“¤ì´#ì—¬í–‰#ì¼ìƒ#íšŒì‹#ê¸°ë…ì¼...")
st.write("")

with st.sidebar:
    st.title('<ì˜µì…˜ì„ ì„ íƒí•˜ë©´ ë¹ ë¥´ê²Œ ì¶”ì²œí•´ë“œë ¤ìš”!>')
    st.write("")
    
    st.subheader('ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”! í•´ë‹¹ ì§€ì—­ì˜ ë§›ì§‘ì„ ì°¾ì•„ë“œë¦´ê»˜ìš”.')
    st.write("")
    
    # ì²´í¬ë°•ìŠ¤ ì‚¬ìš©
    local_jeju_city = st.checkbox('ì œì£¼ì‹œ')  # ì œì£¼ì‹œ ì²´í¬ë°•ìŠ¤
    local_seogwipo_city = st.checkbox('ì„œê·€í¬ì‹œ')  # ì„œê·€í¬ì‹œ ì²´í¬ë°•ìŠ¤
    st.write("")
    
    # PNG ì´ë¯¸ì§€ ì‚½ì… (ì œì£¼ë„ ì§€ë„.png ì´ë¯¸ì§€ ì‚½ì…!!!!!!!!!!!!)
    image = Image.open(r'D:\2024_bigcontest\data\ì´ë¯¸ì§€\ì œì£¼ë„ ì§€ë„.png')  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    st.image(image, caption='ì œì£¼ë„ ì§€ë„', use_column_width=True)  # ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ ì‚½ì…

# Store LLM generated responses
if "messages" not in st.session_state:
    st.session_state.messages = []

# Check if the initial assistant message has been displayed
if "message_displayed" not in st.session_state:
    st.session_state.message_displayed = False

# Display the initial assistant message only once
if not st.session_state.message_displayed:
    st.session_state.messages.append({"role": "assistant", "content": "ì—¬í–‰ ì¤‘ ì œì£¼ ë§›ì§‘ ì¶”ì²œì´ í•„ìš”í•˜ì‹ ê°€ìš”? ì €í¬ ì±—ë´‡ì€ ì‚¬ìš©ìì˜ í•„ìš”ì— ë§ì¶˜ ë§›ì§‘ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."})
    st.session_state.message_displayed = True  # Mark message as displayed
 
for message in st.session_state.messages:  
    with st.chat_message(message["role"]):
        st.write(message["content"])
               
def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ì—¬í–‰ ì¤‘ ì œì£¼ ë§›ì§‘ ì¶”ì²œì´ í•„ìš”í•˜ì‹ ê°€ìš”? ì €í¬ ì±—ë´‡ì€ ì‚¬ìš©ìì˜ í•„ìš”ì— ë§ì¶˜ ë§›ì§‘ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."}]
st.sidebar.button('Clear Chat History', on_click=clear_chat_history)
########################### ê²€ìƒ‰í˜• ë°ì´í„° csv ########################### 
# í•´ë‹¹ ë°ì´í„° ê²½ë¡œë¡œ ë³€ê²½ í•˜ì„¸ìš”!!   
path = r'D:\2024_bigcontest\data\final_data\JEJU_MCT_DATA_v2(12ì›”)_v2.csv'
raw = pd.read_csv(path, index_col = 0)
df = raw.copy()
#########################ì„ë² ë”© ëª¨ë¸ ë¡œë“œ##############################    
embedding_function = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')
#############################ChromaDB##############################    
# ChromaDB ë¶ˆëŸ¬ì˜¤ê¸°
# í•´ë‹¹ ë°ì´í„° ê²½ë¡œë¡œ ë³€ê²½ í•˜ì„¸ìš”!!
recommendation_store = Chroma(
    collection_name='jeju_store_mct_keyword_6',
    embedding_function=embedding_function,
    persist_directory= r'D:\2024_bigcontest\VectorDB\mct_keyword_v6'
)
# metadata ì„¤ì •
metadata = recommendation_store.get(include=['metadatas'])
###########################################ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬################################################
# ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¥¸ ê²€ìƒ‰
if user_input := st.chat_input('ì‚¬ìš©ì íŠ¹ì„±ì´ë‚˜ ì—¬í–‰ ë™ë°˜ì, ìœ„ì¹˜ì™€ ê°™ì€ ì¡°ê±´ì„ ì…ë ¥í•´ë³´ì„¸ìš”.'):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)
        
    with st.spinner("ìŒì‹ì ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):    
        # ìŒì‹ì  ê²€ìƒ‰ ë° ê²°ê³¼ ë°˜í™˜
        response = main(user_input, df)
        
        # ì‚¬ìš©ìê°€ ì œì£¼ì‹œë¥¼ ì„ íƒí•˜ê³  ì„œê·€í¬ì‹œ ìŒì‹ì ì„ ìš”ì²­í•œ ê²½ìš°
        if (local_jeju_city) and (not local_seogwipo_city) and ('ì„œê·€í¬' in user_input):
            assistant_response = "ì œì£¼ì‹œì— ìˆëŠ” ìŒì‹ì ë§Œ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì„œê·€í¬ì‹œì— ìˆëŠ” ìŒì‹ì ì„ ì¶”ì²œë°›ê³  ì‹¶ë‹¤ë©´ ì„œê·€í¬ì‹œì— ì²´í¬í•´ì£¼ì„¸ìš”."
        
        # ì‚¬ìš©ìê°€ ì„œê·€í¬ì‹œë¥¼ ì„ íƒí•˜ê³  ì œì£¼ì‹œì— ìˆëŠ” ìŒì‹ì ì„ ìš”ì²­í•œ ê²½ìš°
        elif (local_seogwipo_city) and (not local_jeju_city) and ('ì œì£¼' in user_input):
            assistant_response = "ì„œê·€í¬ì‹œì— ìˆëŠ” ìŒì‹ì ë§Œ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì œì£¼ì‹œì— ìˆëŠ” ìŒì‹ì ì„ ì¶”ì²œë°›ê³  ì‹¶ë‹¤ë©´ ì œì£¼ì‹œì— ì²´í¬í•´ì£¼ì„¸ìš”."

        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        elif response:
            assistant_response = response  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ assistant_responseë¡œ ì €ì¥
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ
        else:
            assistant_response = main(user_input, df)

    # ì±—ë´‡ ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": assistant_response})

    # ì±—ë´‡ ì‘ë‹µ ì¶œë ¥
    with st.chat_message("assistant"):
        st.write(assistant_response)