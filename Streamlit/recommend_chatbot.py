import streamlit as st 
import pandas as pd
import torch
import os
from PIL import Image
##################################################################api
from dotenv import load_dotenv
import google.generativeai as genai
##################################################################vectordb
import chromadb
from langchain_chroma import Chroma
##################################################################embedding
from transformers import AutoTokenizer, AutoModel
from langchain_community.embeddings import HuggingFaceEmbeddings
from sentence_transformers import SentenceTransformer

load_dotenv()

gemini_api_key = os.getenv('GEMINI_API_KEY')
genai.configure(api_key=gemini_api_key)

##################################################################
#chatbot UI
st.set_page_config(page_title='ì œì£¼ë„ ë§›ì§‘', page_icon="ğŸ†",initial_sidebar_state="expanded")
st.title('ì œì£¼ë„ ìŒì‹ì  íƒë°©!')
st.subheader("ëˆ„êµ¬ë‘ ì œì£¼ë„ ì™”ë‚˜ìš”? ë§ì¶¤ ì œì£¼ë„ ë§›ì§‘ ì¶”ì²œí•´ë“œë ¤ìš”~")

st.write("")

st.write("#ì—°ì¸#ì•„ì´#ì¹œêµ¬#ë¶€ëª¨ë‹˜#í˜¼ì#ë°˜ë ¤ë™ë¬¼ #ë°ì´íŠ¸#ë‚˜ë“¤ì´#ì—¬í–‰#ì¼ìƒ#íšŒì‹#ê¸°ë…ì¼...")
st.write("")

with st.sidebar:
    st.title('<ì˜µì…˜ì„ ì„ íƒí•˜ë©´ ë¹ ë¥´ê²Œ ì¶”ì²œí•´ë“œë ¤ìš”!>')
    st.write("")
    
    st.subheader('ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”! í•´ë‹¹ ì§€ì—­ì˜ ë§›ì§‘ì„ ì°¾ì•„ë“œë¦´ê»˜ìš”.')
    st.write("")
    
    # ì²´í¬ë°•ìŠ¤ ì‚¬ìš©
    local_jeju_city = st.checkbox('ì œì£¼ì‹œ')  # ì œì£¼ì‹œ ì²´í¬ë°•ìŠ¤
    local_seogwipo_city = st.checkbox('ì„œê·€í¬ì‹œ')  # ì„œê·€í¬ì‹œ ì²´í¬ë°•ìŠ¤
    st.write("")
    
    st.subheader("ë§›ì§‘ì„ ê³¨ë¼ë³´ì„¸ìš”! ê´€ê´‘ê°ì„ ìœ„í•œ ë§›ì§‘ ë˜ëŠ” í˜„ì§€ì¸ë“¤ì´ ì‚¬ë‘í•˜ëŠ” ë§›ì§‘ì„ ì„ íƒí•  ìˆ˜ ìˆì–´ìš”.")
    st.write("")
    
    # ì²´í¬ë°•ìŠ¤ ì‚¬ìš©
    local_favorites = st.checkbox('ì œì£¼ë„ë¯¼ ë§›ì§‘')  # ì œì£¼ë„ë¯¼ ë§›ì§‘ ì²´í¬ë°•ìŠ¤
    tourist_favorites = st.checkbox('ê´€ê´‘ê° ë§›ì§‘')  # ê´€ê´‘ê° ë§›ì§‘ ì²´í¬ë°•ìŠ¤
    
    st.write('')
    # PNG ì´ë¯¸ì§€ ì‚½ì…
    image = Image.open(r'D:\Yebang\study\2024ë¹…ì½˜í…ŒìŠ¤íŠ¸\ìƒì„±í˜•AIë¶„ì•¼\Code\Streamlit\ì œì£¼ë„ ì§€ë„.png')  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    st.image(image, caption='ì œì£¼ë„ ì§€ë„', use_column_width=True)  # ì‚¬ì´ë“œë°”ì— ì´ë¯¸ì§€ ì‚½ì…

# Store LLM generated responses
if "messages" not in st.session_state.keys():
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?"}]

# Display or clear chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

def clear_chat_history():
    st.session_state.messages = [{"role": "assistant", "content": "ì–´ë–¤ ì‹ë‹¹ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?"}]
st.sidebar.button('Clear Chat History', on_click=clear_chat_history)
  
##################################################################    
#llm í•¨ìˆ˜ 
def get_llm():
    generation_config = {
        "temperature": 1,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
        "response_mime_type": "text/plain",
    }
    llm = genai.GenerativeModel(model_name="gemini-1.5-flash", generation_config=generation_config)
    return llm

#########################ì„ë² ë”© ëª¨ë¸ ë¡œë“œ##############################    
@st.cache_resource
def load_embedding_model():
    model_name = "jhgan/ko-sroberta-multitask"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    embedding_function = HuggingFaceEmbeddings(model_name=model_name)
    return tokenizer, model, embedding_function

tokenizer, model, embedding_function = load_embedding_model()

#########################ì„ë² ë”© í•¨ìˆ˜##############################    
# í…ìŠ¤íŠ¸ ì„ë² ë”©
def embed_text(text):
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)
    with torch.no_grad():
        embeddings = model(**inputs).last_hidden_state.mean(dim=1)
    return embeddings.squeeze().cpu().numpy()

###########################ChromaDB#############################
search_store = Chroma(
    collection_name="jeju_store_mct_keyword_v4",
    embedding_function=embedding_function,
    persist_directory= r'D:\Yebang\study\2024ë¹…ì½˜í…ŒìŠ¤íŠ¸\ìƒì„±í˜•AIë¶„ì•¼\VectorDB\mct_keyword_v3'
)  
###########################retreiver##########################
def create_filter(local_jeju_city, local_seogwipo_city, local_favorites, tourist_favorites):
    filters = {}

    # 2ê°€ì§€ê°€ ë™ì‹œì— ì²´í¬ëœ ê²½ìš° ì²˜ë¦¬
    if local_jeju_city and local_favorites: #ì œì£¼ì‹œ + í˜„ì§€ì¸ ë§›ì§‘
        filters["address"] = {"$contains": "ì œì£¼ì‹œ"}
        filters["í˜„ì§€ì¸"] = {"$contains": 1}  
    elif local_jeju_city and tourist_favorites: #ì œì£¼ì‹œ + ê´€ê´‘ê° ë§›ì§‘
        filters["address"] = {"$contains": "ì œì£¼ì‹œ"}
        filters["í˜„ì§€ì¸"] = {"$contains": 0}  
    elif local_seogwipo_city and local_favorites: #ì„œê·€í¬ì‹œ + í˜„ì§€ì¸ ë§›ì§‘
        filters["address"] = {"$contains": "ì„œê·€í¬ì‹œ"}
        filters["í˜„ì§€ì¸"] = {"$contains": 1}  
    elif local_seogwipo_city and tourist_favorites:
        filters["address"] = {"$contains": "ì„œê·€í¬ì‹œ"} #ì„œê·€í¬ì‹œ + ê´€ê´‘ê° ë§›ì§‘
        filters["í˜„ì§€ì¸"] = {"$contains": 0}  

    # 1ê°œë§Œ ì²´í¬ëœ ê²½ìš° ì²˜ë¦¬
    elif local_jeju_city:
        filters["address"] = {"$contains": "ì œì£¼ì‹œ"}  # ì œì£¼ì‹œ
    elif local_seogwipo_city:
        filters["address"] = {"$contains": "ì„œê·€í¬ì‹œ"}  # ì„œê·€í¬ì‹œ
    elif local_favorites:
        filters["í˜„ì§€ì¸"] = {"$contains": 1}  # í˜„ì§€ì¸ ë§›ì§‘
    elif tourist_favorites:
        filters["í˜„ì§€ì¸"] = {"$contains": 0}  # ê´€ê´‘ê° ë§›ì§‘
    return filters

# í•„í„°ë§ ì¡°ê±´ì— ë”°ë¼ retriever ìƒì„± í•¨ìˆ˜
def get_retriever(local_jeju_city, local_seogwipo_city, local_favorites, tourist_favorites):
    filters = create_filter(local_jeju_city, local_seogwipo_city, local_favorites, tourist_favorites)

    search_retriever = search_store.as_retriever(
        search_kwargs={
            'k': 3,
            'filter': filters  # í•„í„° ì¡°ê±´ ì ìš©
        }
    )
    return search_retriever

# ì‚¬ìš©ìê°€ ì„ íƒí•œ ì²´í¬ë°•ìŠ¤ ìƒíƒœë¡œ retriever ê°€ì ¸ì˜¤ê¸°
search_retriever = get_retriever(local_jeju_city, local_seogwipo_city, local_favorites, tourist_favorites)
##################################################################
#  User-provided prompt
# ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¥¸ ê²€ìƒ‰
if user_input := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # ì‚¬ìš©ì ì…ë ¥ì„ ì„ë² ë”©í•˜ì—¬ ChromaDBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    user_input_embedding = embed_text(user_input)  # ì‚¬ìš©ì ì…ë ¥ ì„ë² ë”©
    results = search_store.similarity_search_by_vector(user_input_embedding, k=3)  # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰

    # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ ë° ì¶œë ¥
    if results:
        with st.chat_message("assistant"):
            for result in results:
                st.write(f"ì¶”ì²œ ë§›ì§‘: {result.metadata['name']}")
                st.write(f"ì£¼ì†Œ: {result.metadata['address']}")
                st.write(f"ìš”ì•½: {result.metadata['summary']}")
    else:
        with st.chat_message("assistant"):
            st.write("ì£„ì†¡í•©ë‹ˆë‹¤. ì„ íƒí•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë§›ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")